{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка Llama-factory и необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-27T12:30:43.367463Z",
     "iopub.status.busy": "2024-03-27T12:30:43.367180Z",
     "iopub.status.idle": "2024-03-27T12:30:59.814103Z",
     "shell.execute_reply": "2024-03-27T12:30:59.813044Z",
     "shell.execute_reply.started": "2024-03-27T12:30:43.367439Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:31:01.958435Z",
     "iopub.status.busy": "2024-03-27T12:31:01.957741Z",
     "iopub.status.idle": "2024-03-27T12:31:02.913962Z",
     "shell.execute_reply": "2024-03-27T12:31:02.912671Z",
     "shell.execute_reply.started": "2024-03-27T12:31:01.958405Z"
    }
   },
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:31:04.324993Z",
     "iopub.status.busy": "2024-03-27T12:31:04.324313Z",
     "iopub.status.idle": "2024-03-27T12:32:53.514644Z",
     "shell.execute_reply": "2024-03-27T12:32:53.513504Z",
     "shell.execute_reply.started": "2024-03-27T12:31:04.324958Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd LLaMA-Factory\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:32:55.438595Z",
     "iopub.status.busy": "2024-03-27T12:32:55.437911Z",
     "iopub.status.idle": "2024-03-27T12:33:08.114505Z",
     "shell.execute_reply": "2024-03-27T12:33:08.113367Z",
     "shell.execute_reply.started": "2024-03-27T12:32:55.438560Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install  bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем обе доступные карты видимыми для дальнейшей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:16:31.619351Z",
     "iopub.status.busy": "2024-03-25T13:16:31.618971Z",
     "iopub.status.idle": "2024-03-25T13:16:32.664318Z",
     "shell.execute_reply": "2024-03-25T13:16:32.663339Z",
     "shell.execute_reply.started": "2024-03-25T13:16:31.619321Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:53:57.281918Z",
     "iopub.status.busy": "2024-03-26T17:53:57.281485Z",
     "iopub.status.idle": "2024-03-26T17:53:57.287743Z",
     "shell.execute_reply": "2024-03-26T17:53:57.286474Z",
     "shell.execute_reply.started": "2024-03-26T17:53:57.281878Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:53:59.182753Z",
     "iopub.status.busy": "2024-03-26T17:53:59.181968Z",
     "iopub.status.idle": "2024-03-26T17:54:05.092574Z",
     "shell.execute_reply": "2024-03-26T17:54:05.091280Z",
     "shell.execute_reply.started": "2024-03-26T17:53:59.182708Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T17:35:40.327986Z",
     "iopub.status.busy": "2024-03-26T17:35:40.327549Z",
     "iopub.status.idle": "2024-03-26T17:35:40.356574Z",
     "shell.execute_reply": "2024-03-26T17:35:40.355674Z",
     "shell.execute_reply.started": "2024-03-26T17:35:40.327957Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:33:24.779021Z",
     "iopub.status.busy": "2024-03-27T12:33:24.778618Z",
     "iopub.status.idle": "2024-03-27T12:33:27.735178Z",
     "shell.execute_reply": "2024-03-27T12:33:27.734020Z",
     "shell.execute_reply.started": "2024-03-27T12:33:24.778989Z"
    }
   },
   "outputs": [],
   "source": [
    "!wandb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:10:06.182638Z",
     "iopub.status.busy": "2024-03-28T08:10:06.181632Z",
     "iopub.status.idle": "2024-03-28T08:10:39.482815Z",
     "shell.execute_reply": "2024-03-28T08:10:39.481856Z",
     "shell.execute_reply.started": "2024-03-28T08:10:06.182605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e4de12a7ed4ce18028ab2088913dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4190d51225304c5c8379e3909c1e548e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset gazeta_dataset/default (download: 636.08 MiB, generated: 632.97 MiB, post-processed: Unknown size, total: 1.24 GiB) to /root/.cache/huggingface/datasets/IlyaGusev___gazeta_dataset/default/2.0.0/e2d171980aa248bc22e0af4f8485ad69071fc8e5f3d54a253c71eb434f6694bd...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591f2cf3faa4451b8b7cbefedfc99ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c27163811a04de593d46adb7d739838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/550M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4983870133834c09bfb7e832e44566e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/56.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1809c9d9673a4ff0aa69e40e0546733c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/61.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83564ffc6444f82bcdc96219d90dc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/6369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset gazeta_dataset downloaded and prepared to /root/.cache/huggingface/datasets/IlyaGusev___gazeta_dataset/default/2.0.0/e2d171980aa248bc22e0af4f8485ad69071fc8e5f3d54a253c71eb434f6694bd. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import json\n",
    "\n",
    "dataset = load_dataset(\"IlyaGusev/gazeta\", split = 'train[:2000]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовим файл gazeta.json для его дальнейшего использорвания в Llama-factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:34:11.660794Z",
     "iopub.status.busy": "2024-03-27T12:34:11.659909Z",
     "iopub.status.idle": "2024-03-27T12:35:47.197503Z",
     "shell.execute_reply": "2024-03-27T12:35:47.195719Z",
     "shell.execute_reply.started": "2024-03-27T12:34:11.660760Z"
    }
   },
   "outputs": [],
   "source": [
    "save_path = \"/kaggle/working/LLaMA-Factory/data\"  \n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "def save_as_json(data, filename):\n",
    "    file_path = os.path.join(save_path, filename)\n",
    "    data_to_save = [{\n",
    "        \"instruction\": \"Тебе на вход поступает русскоязычная статья из газеты. Твоя задача - выполнить суммаризацию этой статьи.\",\n",
    "        \"input\": data['text'][item],\n",
    "        \"output\": data['summary'][item]\n",
    "    } for item in range(len(dataset['text']))]\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_to_save, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "save_as_json(dataset, 'gazeta.json')\n",
    "#save_as_json(dataset['validation'], 'validation.json')\n",
    "#save_as_json(dataset['test'], 'test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:49.807999Z",
     "iopub.status.busy": "2024-03-27T12:35:49.807605Z",
     "iopub.status.idle": "2024-03-27T12:35:49.814333Z",
     "shell.execute_reply": "2024-03-27T12:35:49.813358Z",
     "shell.execute_reply.started": "2024-03-27T12:35:49.807970Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/LLaMA-Factory/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# В репозитории Llama-factory есть уже предзагруженные наборы данных, добавим туда и набор данных Gazeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:51.547310Z",
     "iopub.status.busy": "2024-03-27T12:35:51.546941Z",
     "iopub.status.idle": "2024-03-27T12:35:51.561081Z",
     "shell.execute_reply": "2024-03-27T12:35:51.560184Z",
     "shell.execute_reply.started": "2024-03-27T12:35:51.547281Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile dataset_info.json\n",
    "{\n",
    "  \"gazeta\": {\n",
    "    \"file_name\": \"gazeta.json\",\n",
    "    \"file_sha1\": \"\"\n",
    "  },\n",
    "  \"alpaca_en\": {\n",
    "    \"file_name\": \"alpaca_data_en_52k.json\",\n",
    "    \"file_sha1\": \"607f94a7f581341e59685aef32f531095232cf23\"\n",
    "  },\n",
    "  \"alpaca_zh\": {\n",
    "    \"file_name\": \"alpaca_data_zh_51k.json\",\n",
    "    \"file_sha1\": \"0016a4df88f523aad8dc004ada7575896824a0dc\"\n",
    "  },\n",
    "  \"alpaca_gpt4_en\": {\n",
    "    \"file_name\": \"alpaca_gpt4_data_en.json\",\n",
    "    \"file_sha1\": \"647f4ad447bd993e4b6b6223d1be15208bab694a\"\n",
    "  },\n",
    "  \"alpaca_gpt4_zh\": {\n",
    "    \"file_name\": \"alpaca_gpt4_data_zh.json\",\n",
    "    \"file_sha1\": \"3eaa3bda364ccdd59925d7448a698256c31ef845\"\n",
    "  },\n",
    "  \"identity\": {\n",
    "    \"file_name\": \"identity.json\",\n",
    "    \"file_sha1\": \"ffe3ecb58ab642da33fbb514d5e6188f1469ad40\"\n",
    "  },\n",
    "  \"oaast_sft\": {\n",
    "    \"file_name\": \"oaast_sft.json\",\n",
    "    \"file_sha1\": \"7baf5d43e67a91f9bbdf4e400dbe033b87e9757e\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    }\n",
    "  },\n",
    "  \"oaast_sft_zh\": {\n",
    "    \"file_name\": \"oaast_sft_zh.json\",\n",
    "    \"file_sha1\": \"a6a91f18f80f37b10ded9cf633fb50c033bf7b9f\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    }\n",
    "  },\n",
    "  \"lima\": {\n",
    "    \"file_name\": \"lima.json\",\n",
    "    \"file_sha1\": \"9db59f6b7007dc4b17529fc63379b9cd61640f37\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    }\n",
    "  },\n",
    "  \"glaive_toolcall\": {\n",
    "    \"file_name\": \"glaive_toolcall_10k.json\",\n",
    "    \"file_sha1\": \"a6917b85d209df98d31fdecb253c79ebc440f6f3\",\n",
    "    \"formatting\": \"sharegpt\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"conversations\",\n",
    "      \"tools\": \"tools\"\n",
    "    }\n",
    "  },\n",
    "  \"example\": {\n",
    "    \"script_url\": \"example_dataset\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    }\n",
    "  },\n",
    "  \"guanaco\": {\n",
    "    \"hf_hub_url\": \"JosephusCheung/GuanacoDataset\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/GuanacoDataset\"\n",
    "  },\n",
    "  \"belle_2m\": {\n",
    "    \"hf_hub_url\": \"BelleGroup/train_2M_CN\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/train_2M_CN\"\n",
    "  },\n",
    "  \"belle_1m\": {\n",
    "    \"hf_hub_url\": \"BelleGroup/train_1M_CN\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/train_1M_CN\"\n",
    "  },\n",
    "  \"belle_0.5m\": {\n",
    "    \"hf_hub_url\": \"BelleGroup/train_0.5M_CN\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/train_0.5M_CN\"\n",
    "  },\n",
    "  \"belle_dialog\": {\n",
    "    \"hf_hub_url\": \"BelleGroup/generated_chat_0.4M\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/generated_chat_0.4M\"\n",
    "  },\n",
    "  \"belle_math\": {\n",
    "    \"hf_hub_url\": \"BelleGroup/school_math_0.25M\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/school_math_0.25M\"\n",
    "  },\n",
    "  \"belle_multiturn\": {\n",
    "    \"script_url\": \"belle_multiturn\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"ultra_chat\": {\n",
    "    \"script_url\": \"ultra_chat\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"open_platypus\": {\n",
    "    \"hf_hub_url\": \"garage-bAInd/Open-Platypus\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/Open-Platypus\"\n",
    "  },\n",
    "  \"codealpaca\": {\n",
    "    \"hf_hub_url\": \"sahil2801/CodeAlpaca-20k\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/CodeAlpaca-20k\"\n",
    "  },\n",
    "  \"alpaca_cot\": {\n",
    "    \"hf_hub_url\": \"QingyiSi/Alpaca-CoT\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/Alpaca-CoT\"\n",
    "  },\n",
    "  \"openorca\": {\n",
    "    \"hf_hub_url\": \"Open-Orca/OpenOrca\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/OpenOrca\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"question\",\n",
    "      \"response\": \"response\",\n",
    "      \"system\": \"system_prompt\"\n",
    "    }\n",
    "  },\n",
    "  \"slimorca\": {\n",
    "    \"hf_hub_url\": \"Open-Orca/SlimOrca\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"mathinstruct\": {\n",
    "    \"hf_hub_url\": \"TIGER-Lab/MathInstruct\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/MathInstruct\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  },\n",
    "  \"firefly\": {\n",
    "    \"hf_hub_url\": \"YeungNLP/firefly-train-1.1M\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"input\",\n",
    "      \"response\": \"target\"\n",
    "    }\n",
    "  },\n",
    "  \"wikiqa\": {\n",
    "    \"hf_hub_url\": \"wiki_qa\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"question\",\n",
    "      \"response\": \"answer\"\n",
    "    }\n",
    "  },\n",
    "  \"webqa\": {\n",
    "    \"hf_hub_url\": \"suolyer/webqa\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/webqa\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  },\n",
    "  \"webnovel\": {\n",
    "    \"hf_hub_url\": \"zxbsmk/webnovel_cn\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/webnovel_cn\"\n",
    "  },\n",
    "  \"nectar_sft\": {\n",
    "    \"hf_hub_url\": \"mlinmg/SFT-Nectar\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/SFT-Nectar\"\n",
    "  },\n",
    "  \"deepctrl\": {\n",
    "    \"ms_hub_url\": \"deepctrl/deepctrl-sft-data\"\n",
    "  },\n",
    "  \"adgen\": {\n",
    "    \"hf_hub_url\": \"HasturOfficial/adgen\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/adgen\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"content\",\n",
    "      \"response\": \"summary\"\n",
    "    }\n",
    "  },\n",
    "  \"sharegpt_hyper\": {\n",
    "    \"hf_hub_url\": \"totally-not-an-llm/sharegpt-hyperfiltered-3k\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"sharegpt4\": {\n",
    "    \"hf_hub_url\": \"shibing624/sharegpt_gpt4\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/sharegpt_gpt4\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"ultrachat_200k\": {\n",
    "    \"hf_hub_url\": \"HuggingFaceH4/ultrachat_200k\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/ultrachat_200k\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"messages\"\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"role_tag\": \"role\",\n",
    "      \"content_tag\": \"content\",\n",
    "      \"user_tag\": \"user\",\n",
    "      \"assistant_tag\": \"assistant\"\n",
    "    },\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"agent_instruct\": {\n",
    "    \"hf_hub_url\": \"THUDM/AgentInstruct\",\n",
    "    \"ms_hub_url\": \"ZhipuAI/AgentInstruct\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"lmsys_chat\": {\n",
    "    \"hf_hub_url\": \"lmsys/lmsys-chat-1m\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/lmsys-chat-1m\",\n",
    "    \"columns\": {\n",
    "      \"messages\": \"conversation\"\n",
    "    },\n",
    "    \"tags\": {\n",
    "      \"role_tag\": \"role\",\n",
    "      \"content_tag\": \"content\",\n",
    "      \"user_tag\": \"human\",\n",
    "      \"assistant_tag\": \"assistant\"\n",
    "    },\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"evol_instruct\": {\n",
    "    \"hf_hub_url\": \"WizardLM/WizardLM_evol_instruct_V2_196k\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/WizardLM_evol_instruct_V2_196k\",\n",
    "    \"formatting\": \"sharegpt\"\n",
    "  },\n",
    "  \"cosmopedia\": {\n",
    "    \"hf_hub_url\": \"HuggingFaceTB/cosmopedia\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"prompt\",\n",
    "      \"response\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"oasst_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/oasst_de\"\n",
    "  },\n",
    "  \"dolly_15k_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/dolly-15k_de\"\n",
    "  },\n",
    "  \"alpaca-gpt4_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/alpaca-gpt4_de\"\n",
    "  },\n",
    "  \"openschnabeltier_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/openschnabeltier_de\"\n",
    "  },\n",
    "  \"evol_instruct_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/evol-instruct_de\"\n",
    "  },\n",
    "  \"dolphin_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/dolphin_de\"\n",
    "  },\n",
    "  \"booksum_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/booksum_de\"\n",
    "  },\n",
    "  \"airoboros_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/airoboros-3.0_de\"\n",
    "  },\n",
    "  \"ultrachat_de\": {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/ultra-chat_de\"\n",
    "  },\n",
    "  \"hh_rlhf_en\": {\n",
    "    \"script_url\": \"hh_rlhf_en\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    },\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"oaast_rm\": {\n",
    "    \"file_name\": \"oaast_rm.json\",\n",
    "    \"file_sha1\": \"622d420e9b70003b210618253bd3d9d2891d86cb\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    },\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"oaast_rm_zh\": {\n",
    "    \"file_name\": \"oaast_rm_zh.json\",\n",
    "    \"file_sha1\": \"1065af1f3784dd61be5e79713a35f427b713a232\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\",\n",
    "      \"history\": \"history\"\n",
    "    },\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"comparison_gpt4_en\": {\n",
    "    \"file_name\": \"comparison_gpt4_data_en.json\",\n",
    "    \"file_sha1\": \"96fa18313544e22444fe20eead7754b17da452ae\",\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"comparison_gpt4_zh\": {\n",
    "    \"file_name\": \"comparison_gpt4_data_zh.json\",\n",
    "    \"file_sha1\": \"515b18ed497199131ddcc1af950345c11dc5c7fd\",\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"nectar_rm\": {\n",
    "    \"hf_hub_url\": \"mlinmg/RLAIF-Nectar\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/RLAIF-Nectar\",\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"orca_dpo_de\" : {\n",
    "    \"hf_hub_url\": \"mayflowergmbh/intel_orca_dpo_pairs_de\",\n",
    "    \"ranking\": true\n",
    "  },\n",
    "  \"wiki_demo\": {\n",
    "    \"file_name\": \"wiki_demo.txt\",\n",
    "    \"file_sha1\": \"e70375e28eda542a90c68213640cc371898ce181\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"c4_demo\": {\n",
    "    \"file_name\": \"c4_demo.json\",\n",
    "    \"file_sha1\": \"a5a0c86759732f9a5238e447fecd74f28a66cca8\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"refinedweb\": {\n",
    "    \"hf_hub_url\": \"tiiuae/falcon-refinedweb\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"content\"\n",
    "    }\n",
    "  },\n",
    "  \"redpajama_v2\": {\n",
    "    \"hf_hub_url\": \"togethercomputer/RedPajama-Data-V2\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"raw_content\"\n",
    "    },\n",
    "    \"subset\": \"default\"\n",
    "  },\n",
    "  \"wikipedia_en\": {\n",
    "    \"hf_hub_url\": \"olm/olm-wikipedia-20221220\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/olm-wikipedia-20221220\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"wikipedia_zh\": {\n",
    "    \"hf_hub_url\": \"pleisto/wikipedia-cn-20230720-filtered\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/wikipedia-cn-20230720-filtered\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"completion\"\n",
    "    }\n",
    "  },\n",
    "  \"pile\": {\n",
    "    \"hf_hub_url\": \"EleutherAI/pile\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/pile\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"text\"\n",
    "    },\n",
    "    \"subset\": \"all\"\n",
    "  },\n",
    "  \"skypile\": {\n",
    "    \"hf_hub_url\": \"Skywork/SkyPile-150B\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/SkyPile-150B\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"text\"\n",
    "    }\n",
    "  },\n",
    "  \"the_stack\": {\n",
    "    \"hf_hub_url\": \"bigcode/the-stack\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/the-stack\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"content\"\n",
    "    }\n",
    "  },\n",
    "  \"starcoder_python\": {\n",
    "    \"hf_hub_url\": \"bigcode/starcoderdata\",\n",
    "    \"ms_hub_url\": \"AI-ModelScope/starcoderdata\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"content\"\n",
    "    },\n",
    "    \"folder\": \"python\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:35:57.272619Z",
     "iopub.status.busy": "2024-03-27T12:35:57.271705Z",
     "iopub.status.idle": "2024-03-27T12:35:59.468014Z",
     "shell.execute_reply": "2024-03-27T12:35:59.466914Z",
     "shell.execute_reply.started": "2024-03-27T12:35:57.272583Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/LLaMA-Factory\n",
    "!wandb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[We supported unsloth's implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models.](https://github.com/hiyouga/LLaMA-Factory/blob/main/README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:36:01.539483Z",
     "iopub.status.busy": "2024-03-27T12:36:01.538745Z",
     "iopub.status.idle": "2024-03-27T12:55:38.392076Z",
     "shell.execute_reply": "2024-03-27T12:55:38.390896Z",
     "shell.execute_reply.started": "2024-03-27T12:36:01.539449Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install \"unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Внесём изменения в конфигурационный файл single_config.yaml, для того, чтобы можно было использовать две видеокарты во время обучения на одном устройсте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:57:23.687904Z",
     "iopub.status.busy": "2024-03-27T12:57:23.687104Z",
     "iopub.status.idle": "2024-03-27T12:57:23.694663Z",
     "shell.execute_reply": "2024-03-27T12:57:23.693489Z",
     "shell.execute_reply.started": "2024-03-27T12:57:23.687871Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile single_config.yaml\n",
    "compute_environment: LOCAL_MACHINE\n",
    "debug: false\n",
    "distributed_type: MULTI_GPU\n",
    "downcast_bf16: 'no'\n",
    "gpu_ids: all\n",
    "machine_rank: 0\n",
    "main_training_function: main\n",
    "mixed_precision: fp16\n",
    "num_machines: 1\n",
    "num_processes: 2\n",
    "rdzv_backend: static\n",
    "same_network: true\n",
    "tpu_env: []\n",
    "tpu_use_cluster: false\n",
    "tpu_use_sudo: false\n",
    "use_cpu: false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:57:27.252300Z",
     "iopub.status.busy": "2024-03-27T12:57:27.251221Z",
     "iopub.status.idle": "2024-03-27T12:57:29.197236Z",
     "shell.execute_reply": "2024-03-27T12:57:29.196384Z",
     "shell.execute_reply.started": "2024-03-27T12:57:27.252265Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:57:30.315720Z",
     "iopub.status.busy": "2024-03-27T12:57:30.315158Z",
     "iopub.status.idle": "2024-03-27T12:57:31.104082Z",
     "shell.execute_reply": "2024-03-27T12:57:31.102788Z",
     "shell.execute_reply.started": "2024-03-27T12:57:30.315687Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:57:34.104288Z",
     "iopub.status.busy": "2024-03-27T12:57:34.103210Z",
     "iopub.status.idle": "2024-03-27T12:57:36.236444Z",
     "shell.execute_reply": "2024-03-27T12:57:36.235459Z",
     "shell.execute_reply.started": "2024-03-27T12:57:34.104250Z"
    }
   },
   "outputs": [],
   "source": [
    "!wandb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T12:59:24.899229Z",
     "iopub.status.busy": "2024-03-27T12:59:24.898821Z",
     "iopub.status.idle": "2024-03-27T15:57:48.460429Z",
     "shell.execute_reply": "2024-03-27T15:57:48.459158Z",
     "shell.execute_reply.started": "2024-03-27T12:59:24.899192Z"
    }
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0,1 accelerate launch \\\n",
    "    --config_file single_config.yaml \\\n",
    "    ../../src/train_bash.py \\\n",
    "    --stage sft \\\n",
    "    --do_train \\\n",
    "    --model_name_or_path IlyaGusev/saiga_mistral_7b_merged \\\n",
    "    --dataset gazeta \\\n",
    "    --dataset_dir ../../data \\\n",
    "    --template default \\\n",
    "    --finetuning_type lora \\\n",
    "    --quantization_bit 4 \\\n",
    "    --lora_target all \\\n",
    "    --output_dir results \\\n",
    "    --cutoff_len 2048 \\\n",
    "    --use_unsloth True \\\n",
    "    --overwrite_cache \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --gradient_accumulation_steps 2 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 1000 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --num_train_epochs 2.0 \\\n",
    "    --output_dir ../../saves/Saiga-7b/QloRA-4bit/sft \\\n",
    "    --overwrite_output_dir True \\\n",
    "    --plot_loss \\\n",
    "    --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T12:32:00.697462Z",
     "iopub.status.busy": "2024-03-26T12:32:00.697079Z",
     "iopub.status.idle": "2024-03-26T12:32:00.705221Z",
     "shell.execute_reply": "2024-03-26T12:32:00.704186Z",
     "shell.execute_reply.started": "2024-03-26T12:32:00.697424Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/LLaMA-Factory/saves/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T16:04:07.408783Z",
     "iopub.status.busy": "2024-03-27T16:04:07.407858Z",
     "iopub.status.idle": "2024-03-27T16:04:13.164035Z",
     "shell.execute_reply": "2024-03-27T16:04:13.162990Z",
     "shell.execute_reply.started": "2024-03-27T16:04:07.408752Z"
    }
   },
   "outputs": [],
   "source": [
    "!zip -r Saiga-2epochs-2048.zip /kaggle/working/LLaMA-Factory/saves/Saiga-7b/QloRA-4bit/sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T16:02:31.715741Z",
     "iopub.status.busy": "2024-03-27T16:02:31.715318Z",
     "iopub.status.idle": "2024-03-27T16:02:31.722956Z",
     "shell.execute_reply": "2024-03-27T16:02:31.722060Z",
     "shell.execute_reply.started": "2024-03-27T16:02:31.715710Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/LLaMA-Factory/saves/Saiga-7b/QloRA-4bit/sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T16:03:58.968489Z",
     "iopub.status.busy": "2024-03-27T16:03:58.968053Z",
     "iopub.status.idle": "2024-03-27T16:03:58.976330Z",
     "shell.execute_reply": "2024-03-27T16:03:58.975246Z",
     "shell.execute_reply.started": "2024-03-27T16:03:58.968456Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T16:02:33.954517Z",
     "iopub.status.busy": "2024-03-27T16:02:33.954121Z",
     "iopub.status.idle": "2024-03-27T16:02:34.965788Z",
     "shell.execute_reply": "2024-03-27T16:02:34.964485Z",
     "shell.execute_reply.started": "2024-03-27T16:02:33.954489Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T15:57:32.585179Z",
     "iopub.status.busy": "2024-03-25T15:57:32.584275Z",
     "iopub.status.idle": "2024-03-25T15:57:32.591244Z",
     "shell.execute_reply": "2024-03-25T15:57:32.590356Z",
     "shell.execute_reply.started": "2024-03-25T15:57:32.585140Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd kaggle/working/LLaMA-Factory/saves/Saiga-7b\n",
    "\"C:\\Users\\yaroslav\\file\\kaggle\\working\\LLaMA-Factory\\saves\\Saiga-7b\\QloRA-4bit\\sft\"\n",
    "\"IlyaGusev/saiga_mistral_7b_merged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:04:17.515653Z",
     "iopub.status.busy": "2024-03-28T08:04:17.515364Z",
     "iopub.status.idle": "2024-03-28T08:05:21.537758Z",
     "shell.execute_reply": "2024-03-28T08:05:21.536683Z",
     "shell.execute_reply.started": "2024-03-28T08:04:17.515628Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q datasets bitsandbytes einops wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на результаты работы модели с контекстным окном 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:47:59.073508Z",
     "iopub.status.busy": "2024-03-28T08:47:59.073092Z",
     "iopub.status.idle": "2024-03-28T08:48:14.619383Z",
     "shell.execute_reply": "2024-03-28T08:48:14.618450Z",
     "shell.execute_reply.started": "2024-03-28T08:47:59.073474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93f016b2ed4d54a3bd7d38ccb822b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"SouthMemphis/Saiga-lora-2048-2epochs\")\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\").eval()\n",
    "model = PeftModel.from_pretrained(model, \"SouthMemphis/Saiga-lora-2048-2epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:48:26.247528Z",
     "iopub.status.busy": "2024-03-28T08:48:26.246571Z",
     "iopub.status.idle": "2024-03-28T08:48:26.798336Z",
     "shell.execute_reply": "2024-03-28T08:48:26.797492Z",
     "shell.execute_reply.started": "2024-03-28T08:48:26.247492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"SouthMemphis/Saiga-lora-2048-2epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:10:44.877829Z",
     "iopub.status.busy": "2024-03-28T08:10:44.876616Z",
     "iopub.status.idle": "2024-03-28T08:10:44.926965Z",
     "shell.execute_reply": "2024-03-28T08:10:44.926033Z",
     "shell.execute_reply.started": "2024-03-28T08:10:44.877783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Компания Google отказалась от использования на компьютерах своих сотрудников операционной системы Windows. Основная официальная претензия, которую выдвигает Google, – низкая безопасность детища Microsoft. «У нас больше не используется Windows: он недостаточно защищен», — заявил изданию Financial Times один из сотрудников Google. По данным газеты, компания решила оснастить почти 10 000 своих компьютеров другими системами, в частности Mac OS или Linux. Сотрудники, которые не желают переходить с Windows на иные системы, должны получить особое разрешение начальства. Решение об уходе с Windows было принято руководством Google ещё в январе и было связано с хакерскими атаками из Китая. С 2006 года, по соглашению с китайским правительством, Google фильтровал результаты поиска в стране, не давая пользователям находить неблагонадежные, с точки зрения официального Пекина, сайты. К таким страничками власти причислили адрес тибетского правительства в изгнании и правозащитных организаций, выступающих в поддержку духовного лидера Тибета — его святейшества далай-ламы. Но этим дело не обошлось. Компанию постоянно атаковали с целью получить доступ к учетным записям Gmail ведущих китайских правозащитников. И вот 12 января в официальном блоге Google появилось сообщение, что в середине декабря компания пережила особо мощную кибератаку из Китая. Кроме этого учетные записи десятков американских, китайских и европейских пользователей, поддерживающих борьбу за права человека в Китае, были взломаны. Основатель Google Сергей Брин признался, что допустил ошибку, пойдя в 2006 году на поводу у властей КНР, а сама компания перестала цензурировать китайский сегмент интернета. Госсекретарь США Хиллари Клинтон потребовала от китайских властей объяснений. Реакции Китая не последовало. Зато последовала реакция Google. Весной компания закрыла свой офис в Пекине и прекратила работу странички google.cn. Все серверы Google перенесла из Китая в Гонконг. «Такая позиция компании Google есть прямой намек, что она более не готова нести затраты на разгребание проблем на своих серверах, которые возникают от китайских товарищей», — считает директор по развитию группы компаний Hosting Community Алексей Степутенков. Проведенное расследование показало, что доступ к учетным записям Gmail во время хакерской атаки стал возможным из-за уязвимости браузера Microsoft Internet Explorer и нарушения безопасности операционных систем семейства Windows. В связи с этим многих сотрудников перевели с Windows-компьютеров в основном на Mac. «Распространенность Windows сыграла с ним злую шутку, — считает директор департамента аудита компании «Информзащита» Максим Эмм. — Ведь именно из-за того, что на 95% персональных компьютеров в мире стоит операционная система от Microsoft, она стала главной мишенью для злоумышленников». Уязвимости есть в любой операционной системе, затраты на создание вируса тоже примерно одинаковы. Но если вирус написан под MAC OS X, то он даже при благоприятном стечении обстоятельств заразит относительно небольшое количество компьютеров ввиду их малой распространенности. Будь Linux чуть популярнее, у него возникли бы те же самые проблемы, говорит вице-президент Mail.Ru Олег Ильичев. Кроме того, в Mac OS и Linux пользователи работают без прав администратора: такова архитектура системы, напоминает генеральный директор компании «Онланта» Сергей Таран. Поэтому любые действия в отношении системы требуют от пользователя ввода пароля администратора, в том числе установка любого программного компонента, и вредоносного, и «добропорядочного». «А Windows этого пароля просто не спрашивает. Молча поставит — и вот вам «троян», — добавляет Таран. — И эту специфику внутреннего устройства Windows используют все кому не лень, поэтому и количество вирусов для Windows растет катастрофически». Эксперты полагают, что запрет на Windows может быть связан и с планами Google по внедрению системы Chrome OS. На данный момент Chrome OS еще слишком молода, не обкатана и не испробована, чтобы стать очевидным выбором для корпоративных ИТ, считает руководитель направления информационной безопасности компании КРОК Михаил Башлыков. Поэтому вероятно, добавляет Ильичев, что в Google решили дать возможность сотрудникам первыми «обкатать» систему. Однако в любом случае на Chrome в Google перейдут не все и не сразу, ведь «там работают в основном программисты, а Chrome — система для пользователей», рассказывает Таран. Удачным маркетинговым ходом для Chrome OS это тоже не станет, ведь система еще не вышла. Что касается потерь Microsoft, то, вероятно, они будут исключительно имиджевые, считает Ильичев: «Что такое несколько тысяч сотрудников Google на фоне сотен миллионов других пользователей Windows?» Несмотря на отрицательную динамику, доля рынка Windows OS все еще составляет более 90%, напоминает Башлыков, и нанести ей существенный урон способно только продолжительное комплексное воздействие. Другое дело, что уход Google, крупной корпорации, с платформы Microsoft и переход на Mac OS для настольных систем — это сигнал корпоративному рынку, считает Таран. Потому что пока широкого использования Mac OS и Linux для пользовательских рабочих мест в корпоративной практике не встречается. «Это первый пример в истории, когда глобальная корпорация отказывается от операционной системы Windows для всех своих пользователей в пользу Mac OS», — напоминает Эмм.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:10:47.768172Z",
     "iopub.status.busy": "2024-03-28T08:10:47.767808Z",
     "iopub.status.idle": "2024-03-28T08:10:47.811562Z",
     "shell.execute_reply": "2024-03-28T08:10:47.810428Z",
     "shell.execute_reply.started": "2024-03-28T08:10:47.768144Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"Тебе на вход поступает русскоязычная статья из газеты. Твоя задача - выполнить суммаризацию этой статьи. Выдели из статьи наиболее релевантные фрагменты и по ним составь её суммаризацию.\n",
    "\n",
    "### Статья:\n",
    "{dataset['text'][12]}\n",
    "\n",
    "### Её суммаризация:\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:22:11.543596Z",
     "iopub.status.busy": "2024-03-28T08:22:11.542746Z",
     "iopub.status.idle": "2024-03-28T08:23:32.206225Z",
     "shell.execute_reply": "2024-03-28T08:23:32.205251Z",
     "shell.execute_reply.started": "2024-03-28T08:22:11.543553Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google переходит на Mac OS и Linux, так как Windows недостаточно защищен. Эксперты считают, что это первый пример в истории, когда крупная корпорация отказывается от операционной системы Microsoft. Потери Microsoft будут исключительно имиджевыми, считают эксперты.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(model.generate(**model_input, max_new_tokens=600)[0], skip_special_tokens=False)\n",
    "    eval_2 = result[result.find(\"Её суммаризация:\") + len(\"Её суммаризация:\") + 1:result.find(\"</s><s>\")]\n",
    "    print(eval_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:17:23.083319Z",
     "iopub.status.busy": "2024-03-28T08:17:23.082948Z",
     "iopub.status.idle": "2024-03-28T08:17:38.227417Z",
     "shell.execute_reply": "2024-03-28T08:17:38.226289Z",
     "shell.execute_reply.started": "2024-03-28T08:17:23.083282Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=9a4f31e9badc36e6516a8acf6be5bc053f06134ba5e0921d64865a0c73f4c6b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install  rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:23:42.436931Z",
     "iopub.status.busy": "2024-03-28T08:23:42.436250Z",
     "iopub.status.idle": "2024-03-28T08:23:42.449575Z",
     "shell.execute_reply": "2024-03-28T08:23:42.448589Z",
     "shell.execute_reply.started": "2024-03-28T08:23:42.436888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.8571428571428571, recall=0.6666666666666666, fmeasure=0.75), 'rouge2': Score(precision=0.3333333333333333, recall=0.25, fmeasure=0.28571428571428575), 'rougeL': Score(precision=0.7142857142857143, recall=0.5555555555555556, fmeasure=0.6250000000000001), 'rougeLsum': Score(precision=0.7142857142857143, recall=0.5555555555555556, fmeasure=0.6250000000000001)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "scores = scorer.score(dataset['summary'][12], eval_2)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на результаты работы модели с контекстным окном 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:23:51.028358Z",
     "iopub.status.busy": "2024-03-28T08:23:51.027535Z",
     "iopub.status.idle": "2024-03-28T08:24:06.208823Z",
     "shell.execute_reply": "2024-03-28T08:24:06.207999Z",
     "shell.execute_reply.started": "2024-03-28T08:23:51.028325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ed54285d794d64b1a68758f504cdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "config = PeftConfig.from_pretrained(\"SouthMemphis/Saiga-7b-lora-2epochs-1024\")\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, load_in_4bit=True, device_map=\"auto\").eval()\n",
    "model = PeftModel.from_pretrained(model, \"SouthMemphis/Saiga-7b-lora-2epochs-1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:24:08.589130Z",
     "iopub.status.busy": "2024-03-28T08:24:08.588234Z",
     "iopub.status.idle": "2024-03-28T08:24:09.119218Z",
     "shell.execute_reply": "2024-03-28T08:24:09.118360Z",
     "shell.execute_reply.started": "2024-03-28T08:24:08.589087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"SouthMemphis/Saiga-7b-lora-2epochs-1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:24:17.344596Z",
     "iopub.status.busy": "2024-03-28T08:24:17.343627Z",
     "iopub.status.idle": "2024-03-28T08:25:38.304611Z",
     "shell.execute_reply": "2024-03-28T08:25:38.303612Z",
     "shell.execute_reply.started": "2024-03-28T08:24:17.344562Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Компания Google перестанет использовать операционную систему Windows на своих компьютерах. Причиной стала хакерская атака из Китая, которая позволила взломать учетные записи пользователей Gmail. В Google считают, что Windows недостаточно защищен, и сотрудникам предлагают перейти на Mac OS или Linux. Эксперты считают, что Google хочет протестировать новую операционную систему Chrome OS, которая еще не готова к внедрению.\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(model.generate(**model_input, max_new_tokens=600)[0], skip_special_tokens=False)\n",
    "    eval_1 = result[result.find(\"Её суммаризация:\") + len(\"Её суммаризация:\") + 1:result.find(\"</s><s>\")]\n",
    "    print(eval_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:36:23.381333Z",
     "iopub.status.busy": "2024-03-28T08:36:23.380675Z",
     "iopub.status.idle": "2024-03-28T08:36:23.394645Z",
     "shell.execute_reply": "2024-03-28T08:36:23.393420Z",
     "shell.execute_reply.started": "2024-03-28T08:36:23.381299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.8571428571428571, recall=0.6666666666666666, fmeasure=0.75), 'rouge2': Score(precision=0.3333333333333333, recall=0.25, fmeasure=0.28571428571428575), 'rougeL': Score(precision=0.7142857142857143, recall=0.5555555555555556, fmeasure=0.6250000000000001), 'rougeLsum': Score(precision=0.7142857142857143, recall=0.5555555555555556, fmeasure=0.6250000000000001)} {'rouge1': Score(precision=0.7272727272727273, recall=0.8888888888888888, fmeasure=0.7999999999999999), 'rouge2': Score(precision=0.5, recall=0.625, fmeasure=0.5555555555555556), 'rougeL': Score(precision=0.6363636363636364, recall=0.7777777777777778, fmeasure=0.7000000000000001), 'rougeLsum': Score(precision=0.6363636363636364, recall=0.7777777777777778, fmeasure=0.7000000000000001)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
    "scores_for_lcw = scorer.score(dataset['summary'][12], eval_1)\n",
    "print(scores, scores_for_lcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:39:47.359759Z",
     "iopub.status.busy": "2024-03-28T08:39:47.358748Z",
     "iopub.status.idle": "2024-03-28T08:39:47.365696Z",
     "shell.execute_reply": "2024-03-28T08:39:47.364741Z",
     "shell.execute_reply.started": "2024-03-28T08:39:47.359711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rouge1', 'rouge2', 'rougeL', 'rougeLsum']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.rouge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:41:36.956277Z",
     "iopub.status.busy": "2024-03-28T08:41:36.955501Z",
     "iopub.status.idle": "2024-03-28T08:41:36.962489Z",
     "shell.execute_reply": "2024-03-28T08:41:36.961423Z",
     "shell.execute_reply.started": "2024-03-28T08:41:36.956243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "index_labels=['precision', 'recall', 'fmeasure']\n",
    "table_for_first = pd.DataFrame(data=scores, index=index_labels)\n",
    "table_for_second = pd.DataFrame(data=scores_for_lcw, index=index_labels)\n",
    "table_for_first.index.name='Metric'\n",
    "table_for_second.index.name='Metric'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики для модели с длиной контекста 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:41:38.669221Z",
     "iopub.status.busy": "2024-03-28T08:41:38.668871Z",
     "iopub.status.idle": "2024-03-28T08:41:38.680242Z",
     "shell.execute_reply": "2024-03-28T08:41:38.679187Z",
     "shell.execute_reply.started": "2024-03-28T08:41:38.669195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fmeasure</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rouge1    rouge2    rougeL  rougeLsum\n",
       "Metric                                            \n",
       "precision  0.857143  0.333333  0.714286   0.714286\n",
       "recall     0.666667  0.250000  0.555556   0.555556\n",
       "fmeasure   0.750000  0.285714  0.625000   0.625000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики для модели с длиной контекста 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:41:46.616149Z",
     "iopub.status.busy": "2024-03-28T08:41:46.615414Z",
     "iopub.status.idle": "2024-03-28T08:41:46.627879Z",
     "shell.execute_reply": "2024-03-28T08:41:46.626883Z",
     "shell.execute_reply.started": "2024-03-28T08:41:46.616113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fmeasure</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rouge1    rouge2    rougeL  rougeLsum\n",
       "Metric                                            \n",
       "precision  0.727273  0.500000  0.636364   0.636364\n",
       "recall     0.888889  0.625000  0.777778   0.777778\n",
       "fmeasure   0.800000  0.555556  0.700000   0.700000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_for_second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры использования лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:48:34.924247Z",
     "iopub.status.busy": "2024-03-28T08:48:34.923876Z",
     "iopub.status.idle": "2024-03-28T08:48:34.968151Z",
     "shell.execute_reply": "2024-03-28T08:48:34.967122Z",
     "shell.execute_reply.started": "2024-03-28T08:48:34.924218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'После более чем 12-часовых консультаций Совет Безопасности ООН согласовал заявление председателя по израильскому штурму «Флотилии свободы». Совбез осудил захват флотилии, требует немедленно отпустить суда и призывает к проведению международного расследования инцидента, сообщает BBC со ссылкой на дипломатические источники. Экстренное заседание СБ ООН было созвано по инициативе Турции и Ливана после того, как израильские военные перехватили шесть судов шедшего в Газу гуманитарного конвоя. Согласно сообщению минобороны Израиля, при захвате погибли девять человек, ранены еще 33 человека. По информации посольства Израиля в Москве, в операции пострадали 10 израильских военных. В ходе открытого обсуждения Турция выступила с резкой критикой действий Израиля. «Попросту говоря, это равносильно бандитизму и пиратству. Это убийство, осуществленное руками государства», — заявил в ходе заседания турецкий министр иностранных дел Ахмет Давутоглу. «Эта флотилия была чем угодно, только не гуманитарной миссией», — ответил заместитель представителя Израиля в ООН Даниэль Кармон. Сразу после начала выступления представителя Израиля выступавший первым Давутоглу покинул зал заседания. Накануне члены Совбеза ООН — в том числе Великобритания, Россия, Франция и Китай — призвали Израиль снять экономическую блокаду сектора Газа. Соединенные Штаты воздержались. В заявлении представителя США в Совбезе отмечается, что Израиль мог бы смягчить условия блокады палестинской территории. Россия осудила захват кораблей, заявил на заседании первый заместитель постпреда России при ООН Александр Панкин. К настоящему моменту израильские власти задержали 480 человек, которые были пассажирами захваченных судов. 48 человек планируется выдворить из страны, передает во вторник израильское общественное радио. Задержанные находятся в тюрьме израильского города Ашдода, депортируемые направлены в израильский международный аэропорт имени Бен Гуриона. 14 человек, среди которых граждане Марокко, Ливана, США и Австралии, согласились на добровольную депортацию, 80 временно переместились в тюрьму Беэр-Шевы. Задержанных планируется допросить в течение дня, после чего израильские власти решат, кто будет освобожден, а против кого будут выдвинуты обвинения. Тем, кто не согласится на добровольную депортацию, или тем, кто участвовал в нападениях на израильских солдат, предстоят арест и экстрадиция.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:49:04.041230Z",
     "iopub.status.busy": "2024-03-28T08:49:04.040849Z",
     "iopub.status.idle": "2024-03-28T08:49:04.083450Z",
     "shell.execute_reply": "2024-03-28T08:49:04.082531Z",
     "shell.execute_reply.started": "2024-03-28T08:49:04.041201Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"Тебе на вход поступает русскоязычная статья из газеты. Твоя задача - выполнить суммаризацию этой статьи. Выдели из статьи наиболее релевантные фрагменты и по ним составь её суммаризацию.\n",
    "\n",
    "### Статья:\n",
    "{dataset['text'][2]}\n",
    "\n",
    "### Её суммаризация:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:52:01.720417Z",
     "iopub.status.busy": "2024-03-28T08:52:01.720118Z",
     "iopub.status.idle": "2024-03-28T08:53:19.036374Z",
     "shell.execute_reply": "2024-03-28T08:53:19.035231Z",
     "shell.execute_reply.started": "2024-03-28T08:52:01.720392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Совет Безопасности ООН осудил захват израильскими военными гуманитарной флотилии, требуя немедленно отпустить суда и провести международное расследование инцидента. Турция и Ливан созвали экстренное заседание Совбеза ООН, на котором Турция назвала действия Израиля «пиратством» и «убийством». Россия также осудила захват кораблей, заявив, что Израиль нарушил международное право. Израильские власти задержали 480 человек, из которых 48 планируется депортировать.\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(model.generate(**model_input, max_new_tokens=600)[0], skip_special_tokens=False)\n",
    "    eval = result[result.find(\"Её суммаризация:\") + len(\"Её суммаризация:\") + 1:result.find(\"</s><s>\")]\n",
    "    print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:54:11.328594Z",
     "iopub.status.busy": "2024-03-28T08:54:11.328208Z",
     "iopub.status.idle": "2024-03-28T08:54:11.373398Z",
     "shell.execute_reply": "2024-03-28T08:54:11.372340Z",
     "shell.execute_reply.started": "2024-03-28T08:54:11.328563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Глава правительства Японии Юкио Хатояма официально объявил о намерении уйти в отставку, передает ИТАР-ТАСС со ссылкой на телеканал NCHK. О своем решении он уже уведомил возглавляемую им Демократическую партию Японии. Хатояма принес извинения избирателям за то, что не смог выполнить предвыборное обещание — вывести американскую базу Футэмма за пределы префектуры Окинава. «Я приношу извинения за то, что нам не удалось вывести базу Футэмма за пределы префектуры Окинава, но мы продолжим к этому стремиться», — заявил глава правительства. «В современных условиях японо-американское сотрудничество необходимо для обеспечения безопасности не только нашей страны, но и всего региона», — пояснил он. Вместе с премьер-министром решил уйти в отставку генеральный секретарь ДПЯ Итиро Одзава. Он выразил надежду, что благодаря усилиям партии в стране станет обязательно лучше, и пригласил Социал-демократическую партию, вышедшую из правящей коалиции 30 мая, вернуться к сотрудничеству. Перенос американской военной базы Футэмма стал одним из предвыборных лозунгов Демпартии на выборах в сентябре прошлого года. Однако в ноябре на переговорах американский президент Барак Обама и Хатояма обошли этот вопрос стороной. На прошлой неделе японский премьер-министр объявил, что вывести базу из префектуры Окинава невозможно, однако она будет передислоцирована в менее населенный район одноименного острова. После этого решения в правящей коалиции начался разлад — не все согласились подписывать документ о передислокации базы. Глава социал-демократов Мидзухо Фукусиму была уволена с поста министра по делам потребителей за отказ подписывать документ. В ответ на это руководство Социал-демократической партии приняло решение о выходе из коалиции. К решению Хатоямы политические круги страны отнеслись неоднозначно. «Я сожалею. Премьер-министр Хатояма предпринял множество мер, в частности, выдачу пособий на детей и другие. И мог бы заслужить более высокую оценку со стороны народа», — заявил перед журналистами заместитель главы комитета по парламентской политике Вакио Мицуи, сообщает РИА «Новости». Оппозиционная Либерально-демократическая партия считает, что так демократы решили «подкрасить фасад» перед выборами в верхнюю палату парламента, которые состоятся в июле. «Отставка именно сейчас (преследует) исключительно предвыборные цели. Я считаю, что необходимо спросить мнение народа о доверии (партии демократов)», — заявил на пресс-конференции председатель ЛДП Садакадзу Танигаки. Демократическая партия победила на досрочных выборах в парламент в сентябре 2009 года, серьезно опередив правящую на тот момент ЛДПЯ. Причиной поражения стал финансовый кризис. После победы демократов Хатояма был утвержден премьер-министром. Сейчас уже звучат призывы провести очередные досрочные выборы в нижнюю палату, поскольку Демпартия не оправдала доверия избирателей. Однако решения по этому вопросу пока нет.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:54:30.834333Z",
     "iopub.status.busy": "2024-03-28T08:54:30.833942Z",
     "iopub.status.idle": "2024-03-28T08:54:30.877159Z",
     "shell.execute_reply": "2024-03-28T08:54:30.876223Z",
     "shell.execute_reply.started": "2024-03-28T08:54:30.834301Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"Тебе на вход поступает русскоязычная статья из газеты. Твоя задача - выполнить суммаризацию этой статьи. Выдели из статьи наиболее релевантные фрагменты и по ним составь её суммаризацию.\n",
    "\n",
    "### Статья:\n",
    "{dataset['text'][27]}\n",
    "\n",
    "### Её суммаризация:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:54:32.207095Z",
     "iopub.status.busy": "2024-03-28T08:54:32.206103Z",
     "iopub.status.idle": "2024-03-28T08:55:50.094937Z",
     "shell.execute_reply": "2024-03-28T08:55:50.093785Z",
     "shell.execute_reply.started": "2024-03-28T08:54:32.207047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Премьер-министр Японии Юкио Хатояма объявил о намерении уйти в отставку. Он не смог выполнить обещание вывести американскую базу Футэмма за пределы префектуры Окинава. Вместе с Хатоямой уходит в отставку генеральный секретарь его партии Итиро Одзава. Политические круги Японии считают, что демократы решили «подкрасить фасад» перед выборами в верхнюю палату парламента.\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(model.generate(**model_input, max_new_tokens=600)[0], skip_special_tokens=False)\n",
    "    eval = result[result.find(\"Её суммаризация:\") + len(\"Её суммаризация:\") + 1:result.find(\"</s><s>\")]\n",
    "    print(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:56:57.004149Z",
     "iopub.status.busy": "2024-03-28T08:56:57.003702Z",
     "iopub.status.idle": "2024-03-28T08:56:57.050684Z",
     "shell.execute_reply": "2024-03-28T08:56:57.049657Z",
     "shell.execute_reply.started": "2024-03-28T08:56:57.004118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В России произошло второе самоубийство школьника в период сдачи ЕГЭ. В Москве в ночь на среду около 22.09 из окна седьмого этажа дома № 4 на Пулковской улице выпрыгнул 16-летний ученик московской школы № 224. Дом подростка и его школа находятся на станции метро «Водный стадион». 31 мая школьник сдавал обязательный госэкзамен по русскому языку. По факту самоубийства Следственный комитет по Москве (СКП) проводит доследственную проверку. Как рассказали «Газете.Ru» в пресс-службе ведомства, до госэкзамена школьник очень беспокоился о его результатах и «высказывал родителям мысли о суициде». По данным СКП, 1 июня между 21.00 и 22.00 подросток разговаривал с родителями и вновь сказал отцу, что собирается покончить с собой. Отец не дал школьнику выйти на улицу, разгорелась ссора. Подросток оттолкнул отца и бабушку, стоящих около него, вбежал в общую с младшей сестрой комнату и выпрыгнул с балкона. Префект САО Олег Митволь сказал «Газете.Ru», что, по информации из образовательных и правоохранительных органов, родители не выпустили в тот вечер ребенка погулять, потому что ему надо было готовиться к следующему госэкзамену. «Между ним и отцом возник межличностный конфликт. Он выбросился на глазах у младшей сестры. Мы расследуем этот инцидент параллельно с органами внутренних дел », — рассказал префект. Он добавил, что одноклассникам школьник также неоднократно говорил о самоубийстве. «Неправильно сказать, что он покончил с собой из-за ЕГЭ. Над его школой шефствует Московский авиационный институт , и, как я понял, школьников готовят к поступлению именно туда», — сказал также Митволь. Директор школы № 224 Ольга Гинесина сообщила «Газете.Ru», что после экзамена одна из учителей на пункте приема спросила школьника, как он оценивает свою работу, на что ученик ответил, что, как ему кажется, результаты по русскому языку (предмет, также необходим для поступления в любой вуз страны) у него будут хорошими. «Это хороший ребенок, с хорошей успеваемостью, абсолютно бесконфликтный», — сказала директор. С самого утра в школе в рамках доследственной проверки по факту смерти Евгения Голобородько (так, по данным «Русской службы новостей», звали подростка) работают следователи. Выступавший в среду в рамках правительственного часа в Госдуме министр образования Андрей Фурсенко заявил, что самоубийство Голобородько не надо связывать с ЕГЭ. «Этот конкретный случай не связан с экзаменом хотя бы потому, что мальчик не мог знать результат», — пояснил министр. Напомним, что это уже второй случай самоубийства школьника во время стартовавшей в России 27 мая основной волны ЕГЭ. Ранее в гараже в Воронежской области повесился выпускник средней школы села Новая Покровка Семилукского района. «По предварительным данным, юноша не выдержал сильного нервного напряжения перед сдачей ЕГЭ по русскому языку. В середине мая он неудачно сдал пробный экзамен, после чего замкнулся в себе и сильно переживал случившееся», — говорится на сайте Генпрокуратуры. Директор областного департамента образования, науки и молодежной политики Олег Мосолов информацию правоохранительных органов опроверг. «Информация о том, что у него были проблемы с пробным экзаменом, не соответствует действительности, потому что пробного экзамена по русскому не было. Был пробный экзамен по математике, на котором отрабатывалась технология работы с контрольно-измерительными материалами. Данный экзамен не оценивался», — сказал он РИА «Новости». Он также отметил, что учителя не оказывали на него давления, учился он удовлетворительно и сомнений по поводу того, что школьник сможет сдать ЕГЭ, ни у кого не было. «Эта семья находилась на контроле в школе, как семья, которая вызывала определенные опасения с точки зрения благополучия. По этому факту я могу предъявить документы: данные школьного учета, докладные руководителей школы, карточки учета», — добавил Мосолов.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:57:13.857313Z",
     "iopub.status.busy": "2024-03-28T08:57:13.856602Z",
     "iopub.status.idle": "2024-03-28T08:57:13.899916Z",
     "shell.execute_reply": "2024-03-28T08:57:13.899188Z",
     "shell.execute_reply.started": "2024-03-28T08:57:13.857280Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"Тебе на вход поступает русскоязычная статья из газеты. Твоя задача - выполнить суммаризацию этой статьи. Выдели из статьи наиболее релевантные фрагменты и по ним составь её суммаризацию.\n",
    "\n",
    "### Статья:\n",
    "{dataset['text'][33]}\n",
    "\n",
    "### Её суммаризация:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T08:57:20.228195Z",
     "iopub.status.busy": "2024-03-28T08:57:20.227803Z",
     "iopub.status.idle": "2024-03-28T08:58:39.038662Z",
     "shell.execute_reply": "2024-03-28T08:58:39.037701Z",
     "shell.execute_reply.started": "2024-03-28T08:57:20.228164Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Во время сдачи ЕГЭ в России произошло второе самоубийство школьника. В Москве 16-летний ученик сдавал экзамен по русскому языку и после его завершения выпрыгнул из окна на седьмом этаже. В СКП говорят, что подросток беспокоился о результатах экзамена и рассказывал родителям о намерении покончить с собой. Министерство образования заявляет, что самоубийство ученика не связано с ЕГЭ.\n"
     ]
    }
   ],
   "source": [
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    result = tokenizer.decode(model.generate(**model_input, max_new_tokens=600)[0], skip_special_tokens=False)\n",
    "    eval = result[result.find(\"Её суммаризация:\") + len(\"Её суммаризация:\") + 1:result.find(\"</s><s>\")]\n",
    "    print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
